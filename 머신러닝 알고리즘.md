# 앙상블
## 앙상블 형태 
1. 보팅 : 보팅은 서로 다른 알고리즘을 가진 분류기를 결합(같은 데이터셋)
2. 배깅 : 각각의 분류기가 모두 같은 유형의 알고리즘 이지만, 데이터 샘플링들 서로 다르게 가져가면서 학습을 수행해 보팅
3. 부스팅 : 앞에서 학습한 분류기가 예측이 틀린 데이터에 대해서 올바르게 예측할 수 있도록 다음 분류기에는 가중치를 부스팅하면서 학습을 진행 
	- 앙상블 학습을 주도함(예측력 좋음)
	- XGBoost(eXtra Gradient Boost), LightGBM(Light Gradient Boost)

## 랜덤포레스트
- 배깅의 대표 알고리즘
- 빠른 수행속도, 
- 여러개의 결정 트리 분류기가 전체 데이터![[IMG_6276.jpg]]

## GBM(Gradient Boosting Machine)
- 부스팅 알고리즘 : 여러개의 약한 학습기를 순차적으로 학습-예측 하면서 잘못 예측한 데이터에 가중치를 부여해 오류를 개선
- 과적합에도 강한 뛰어난 예측성능을 가짐
- 수행시간이 오래걸림

## XGBoost(eXtra Gradient Boost)
- 분류에 있어서 뛰어난 예측 성능
- GBM기반, 
- Tree pruning을 통해 긍정 이득이 없는 분할을 가지치기 해서 분할 수를 더 줄일 수 있음

## LightBGM
- XGBoost보다 학습 시간이 적게 걸림
- 리프 중심 트리분할 방식 사용
- 트리의 균형을 맞추지 않고, 최대 손실값을 가지는 리프노드를 지속적으로 분할 -> 트리 깊이가 깊어지고 비대칭적 규칙트리 생성