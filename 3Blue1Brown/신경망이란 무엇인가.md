신경망 : 사람의 뇌의 신경망에서 따온
- 뉴런 : 0에서 1사이의 숫자 1개를 기록함.
- 뉴런에 큰 값이 주어질 수록 신경망이 더 많이 반응함.

- 0~9까지 손글씨 예측하는 신경망을 예로들때,
- 입력층은 784(28x28) 출력층은 0~9까지의 예측값, 은닉층은 16개의 뉴런을 가진 2개의 층
- 한 층에서의 활성화가 다른 층의 활성화를 가져옴
- 활성화되는 뉴런들의 특정 패턴이 다음 층의 활성화를 가져옴
- ![[스크린샷 2022-11-07 16.08.03.png]]
- 위와 같이 9가 들어오면 작은 조각으로 나눠보고, 위 동그라미와 일자로 나눠서 뉴런을 활성화 시킴
![[Pasted image 20221107161026.png]]
![[Pasted image 20221107161035.png]]
- 가중치를 픽셀에 표현
- 해당 부분의 가중치를 적ㄱ
- 뉴런에 대한 활성화는 시그모이드 함수로 활성화 시킨다

- 만약 값이 10 이상일 때만 활성화 되게 하고 싶다면 bias를 넣는다 식에 -10을 넣어주면 됨. 시그모이드 함수에 입력되기 전에

- 활성화된 정도를 열백터로 나타내고 가중치는 행렬로 나타냄 -> 결과값은 열벡터가 됨,.
- ![[Pasted image 20221107162029.png]]

- 여기에 bias를 더해주고 시그모이드 함수로 감싸주면
- ![[Pasted image 20221107162103.png]]
- 각 뉴런들을 다음과 같은 식으로 쉽게 나타낼 수 있다.![[Pasted image 20221107162114.png]]


- Relu함수 : 임계값을 넘기면 항등함수, 임계값을 넘기지 못하면 0 
	- 시그모이드보다 훨신 깊은 신경망을 학습시킬 수 있음


# 2장 심층학습
잘못된 출력과 원하는 출력의 차이를 비용(cost)라고 부른다.
- 신경망이 자기가 뭘 하고 있는 지 모를때는 이게 커짐
- 